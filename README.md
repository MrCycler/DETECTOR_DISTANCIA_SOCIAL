# DETECTOR DISTANCIA SOCIAL

## Datos del curso 

 **Proyecto parcial**
* **Curso: Computaci贸n Gr谩fica**
* **Clase del 2020-1**
* **Maestr铆a en inform谩tica - Menci贸n en ciencias de la computaci贸n**

## Objetivo 

El proyecto tiene como objetivo desarrollar una pieza de c贸digo capaz de recibir como entrada un video de una calle concurrida en Londres y determinar que personas mostradas en el video cumplen con una normativa de distancia social y cuales no. El video usado se puede encontrar en el siguiente [enlace](http://www.robots.ox.ac.uk/ActiveVision/Research/Projects/2009bbenfold_headpose/Datasets/TownCentreXVID.avi), el cual es material para el desarrollo de algoritmos de detecci贸n en imagenes proporcionado por la universidad de Oxford. Por otro lado, tambien se utiliza la informaci贸n de los puntos que determinan los bounding boxes correspondientes a los cuerpos y cabezas de los transeuntes mostrados en el video anterior. Esta informaci贸n puede ser encontrada en el siguiente [enlace](http://www.robots.ox.ac.uk/ActiveVision/Research/Projects/2009bbenfold_headpose/Datasets/TownCentre-groundtruth.top)

Finalmente el resultado obtenido es un video compuesto de frames como el mostrado a continuaci贸n:

<p align="center"> 
    <img src='Resultados/out.png' alt="Resultado">
</p>


## Arquitectura y estructura de archivos 

El proyecto cuentas con las siguientes carpetas:

 Setup ([Ver](/Archivos%20Setup)) .- Contiene los archivos para la configuraci贸n inicial del entorno para ejecutar los programas.

 Data ([Ver](/Data)) .- En esta carpeta se deben almacenar los archivos para la prueba que son tres: 
- El video donde se realizar谩 la inspecci贸n (video.avi)
- Dos archivos que tiene la informaci贸n de los bounding boxes (caminantes.csv y walkers.txt)

 Experimentos ([Ver](/Experimentos)) .- Contienen los experimentos hechos en jupyter notebooks donde se va probando cada una de las funciones creadas para el proyecto. Estos experimentos son listados a continuaci贸n:

- Experimento 1 ([Ver](/Experimentos/Experimento%201%20-%20Visualizaci贸n%20del%20v铆deo.%20Identificaci贸n%20de%20puntos.ipynb)): Visualizaci贸n del video y marcado de bounding boxes en los frames.
<p align="center"> 
    <img src='Resultados/out1.png' alt="Experimento 1" height="300px" width="600px">
</p>

- Experimento 2 ([Ver](/Experimentos/Experimento%202%20-%20Determinaci贸n%20de%20la%20tranformaci贸n.ipynb)): Determinaci贸n de la matriz de transformaci贸n de la imagen y muestra de la imagen transformada.
<p align="center"> 
    <img src='Resultados/out2.png' alt="Experimento 2" height="400px" width="200px">
</p>

- Experimento 3 ([Ver](/Experimentos/Experimento%203%20-%20Gr谩fica%20de%20puntos%20en%20ojo%20de%20halcon.ipynb)): Se grafican los puntos que representan las cabezas de las personas pero desde una vista denominada ojo de halcon.
<p align="center"> 
    <img src='Resultados/out3a.png' alt="Experimento 3a" height="300px" width="600px">
    <img src='Resultados/out3b.png' alt="Experimento 3b" height="400px" width="200px">
</p>

- Experimento 4 ([Ver](/Experimentos/Experimento%204%20-%20Determinaci贸n%20de%20infractores.ipynb)): Determinaci贸n de infractores. En este experimento se muestran los infractores de color rojo y los que no en color verde. tanto en los frames del video como en la vista de ojo de h谩lcon.
<p align="center"> 
    <img src='Resultados/out4a.png' alt="Experimento 4a" height="300px" width="600px">
    <img src='Resultados/out4b.png' alt="Experimento 4b" height="400px" width="200px">
</p>

- Experimento 5:([Ver](/Experimentos/Experimento%205%20-%20Mejoras.ipynb)): En esta experiencia se a帽aden mejoras como la variaci贸n de la distancia permitida y el trazo de rectas de separaci贸n.
<p align="center"> 
    <img src='Resultados/out5.png' alt="Experimento 5a" height="300px" width="600px">
</p>

 Resultados ([Ver](/Resultados)) .- En esta carpeta se almacenan las imagenes que se obtuvieron como resultado de los experimentos.


## Pasos para ejecuci贸n (Colab, Jupyter Notebook) 

### Jupyter Notebook 

- Clonar el proyecto, usar:
`git clone https://github.com/fararay/DETECTOR_DISTANCIA_SOCIAL.git`
- Descargar los archivos del siguiente ([Enlace](/Experimentos/Experimento%205%20-%20Mejoras.ipynb)).
- Mover los archivos en la carpeta Data
- Ejecutar el cuaderno (Programa_Final.ipynb) 

### Colab

- Copiar el archivo (Programa_Final_(Colab).ipynb) a Google Drive
- Descargar los archivos del proyect,usar:
`!wget link1`
`!wget link2`
- Ejecutar el cuaderno 

## Algoritmo

#### El programa desarrollado sigue los siguientes pasos para poder determinar la vista bird-eye

- **Divisi贸n de los frames y trazado de bounding boxes** .- Se usa la librer铆a opencv para poder dividir el video en frames y en base a la informaci贸n del archivo de texto correspondiente se trazan los bounding boxes que envuelven a cada una de las personas en cada frame.
- **Determinaci贸n de la transformaci贸n** .- Realizado en el experimento 2. Se trata de corresponder puntos conocidos de un frame del video original con la forma a la que se quiere llegar finalmente. Este proceso genera una matriz de transformaci贸n la cual ser谩 usada posteriormente. Se aproxima la distancia en unidades reales en la segunda imagen seg煤n el c贸digo mostrado a continuaci贸n:
`#6 lozas de ancho - Aproximamos ancho de 40 cm`
`#15 Lozas de alto - Aproximamos largo de 40 cm`
`pix_unit = 1.7 #pixeles por centimetro`
`width_street = 240*pix_unit`
`height_street = 600*pix_unit`
<p align="center"> 
    <img src='Resultados/base.png' alt="Base" height="300px" width="600px">
</p>
- **Determinaci贸n de puntos representativos** .- Se usa la informaci贸n de los puntos correspondientes a bounding boxes para determinar aproximadamente la posici贸n de la cabeza de una persona en el frame original, asi mismo, se utiliza la matriz de transformaci贸n para ubicar esos puntos en la imagen resultado (bird-eye).
- **Determinaci贸n de puntos buenos y malos** .- En base a una distancia de restricci贸n dada se determinan que puntos que representan a las personas cumplen con la restricci贸n y cuales no, para ello se usa la posici贸n de los puntos en la imagen bird-eye y se determina la distancia simple euclidiana entre ellos.
- **Visualizaci贸n de resultados**.- En base a la informaci贸n de los puntos buenos y malos, se marcan con color rojo aquellos que no cumplen la restricci贸n de distancia en la imagen resultado. Asi mismo, los que si cumplen son mostrados en color verde. El conjunto de puntos buenos y malos tambien determinan el color de los bounding boxes que corresponden a las personas en la imagen original.

## Autor 

<p align="center"> 
    <img src='https://media-exp1.licdn.com/dms/image/C4E03AQFrZ6AE63kEBg/profile-displayphoto-shrink_200_200/0?e=1596672000&v=beta&t=yebfHsJHHxJXedF-WPHQR_dBNU7tddFdJR6Bx8QHu1o' alt="Resultado">
</p>

* **Juan Manuel Mendoza Jacinto** - [Linkedin](https://pe.linkedin.com/in/juan-manuel-mendoza-jacinto-18515ab0) - [Github](https://github.com/fararay)


## Licencia 

La licencia de este proyecto es del tipo **GNU General Public License v3.0** ([Ver](LICENSE.md))


